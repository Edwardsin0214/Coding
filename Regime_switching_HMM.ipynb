{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f84a89f4",
   "metadata": {},
   "source": [
    "## 1. Hidden Markov Model (HMM)\n",
    "\n",
    "Let $Z_t$ be the hidden state at time $t$ where $Z_t \\in \\{0,1,\\dots,K-1\\}$, and let $X_t$ be the observed feature vector.\n",
    "\n",
    "1. **Transition (Markov property)**  \n",
    "$$\n",
    "P(Z_t=j\\mid Z_{t-1}=i)=A_{ij},\\qquad\n",
    "A=\\begin{bmatrix}\n",
    "a_{0,0}&\\cdots&a_{0,K-1}\\\\\n",
    "\\vdots&\\ddots&\\vdots\\\\\n",
    "a_{K-1,0}&\\cdots&a_{K-1,K-1}\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "2. **Emission (Gaussian observation model)**  \n",
    "$$\n",
    "P(X_t\\mid Z_t=k)=\\mathcal N(X_t\\mid \\mu_k,\\Sigma_k).\n",
    "$$\n",
    "\n",
    "3. **Initial distribution (stationary)**  \n",
    "$$\n",
    "\\pi=\n",
    "\\begin{bmatrix}\n",
    "\\pi_0\\\\\n",
    "\\vdots\\\\\n",
    "\\pi_{K-1}\n",
    "\\end{bmatrix},\n",
    "\\qquad\n",
    "\\pi=A^\\top \\pi,\n",
    "\\qquad\n",
    "\\sum_{k=0}^{K-1}\\pi_k=1.\n",
    "$$\n",
    "\n",
    "4. **Joint probability**\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(X_{1:T},Z_{1:T})\n",
    "&=\n",
    "\\underbrace{P(Z_1)}_{\\pi_{Z_1}}\n",
    "\\cdot\n",
    "\\underbrace{P(X_1 \\mid Z_1)}_{\\text{Emission at } t=1}\n",
    "\\cdot\n",
    "\\prod_{t=2}^{T}\n",
    "\\underbrace{P(Z_t \\mid Z_{t-1})}_{A_{Z_{t-1}, Z_t}}\n",
    "\\cdot\n",
    "\\underbrace{P(X_t \\mid Z_t)}_{\\text{Emission at } t}\n",
    "\\\\\n",
    "&=\n",
    "\\pi_{Z_1}\\,P(X_1\\mid Z_1)\\,\n",
    "\\prod_{t=2}^{T} A_{Z_{t-1},Z_t}\\,P(X_t\\mid Z_t).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Learning & Inference\n",
    "\n",
    "#### Goal 1: Learn parameters $\\theta=\\{\\pi,A,\\mu_k,\\Sigma_k\\}$\n",
    "\n",
    "We maximize the data likelihood:\n",
    "$$\n",
    "\\hat\\theta=\\arg\\max_{\\theta} P(X_{1:T}\\mid \\theta)\n",
    "=\n",
    "\\arg\\max_{\\theta}\\sum_{Z_{1:T}} P(X_{1:T},Z_{1:T}\\mid \\theta).\n",
    "$$\n",
    "Solved by **Baum–Welch (EM)**.\n",
    "\n",
    "**EM idea**  \n",
    "E-step: compute how likely each state/transition was.  \n",
    "M-step: update parameters using those likelihood weights.\n",
    "\n",
    "**Model**\n",
    "$$\n",
    "P(X_{1:T},Z_{1:T}\\mid\\theta)\n",
    "=\n",
    "\\pi_{Z_1}\\prod_{t=2}^{T}A_{Z_{t-1},Z_t}\\prod_{t=1}^{T}b_{Z_t}(X_t),\n",
    "\\qquad\n",
    "b_k(x)=\\mathcal N(x\\mid\\mu_k,\\Sigma_k).\n",
    "$$\n",
    "\n",
    "**E-step (forward–backward)**\n",
    "$$\n",
    "\\alpha_1(k)=\\pi_k b_k(X_1),\\qquad\n",
    "\\alpha_{t+1}(j)=\\Big(\\sum_{i=0}^{K-1}\\alpha_t(i)A_{ij}\\Big)\\,b_j(X_{t+1}).\n",
    "$$\n",
    "$$\n",
    "\\beta_T(k)=1,\\qquad\n",
    "\\beta_t(i)=\\sum_{j=0}^{K-1}A_{ij}\\,b_j(X_{t+1})\\,\\beta_{t+1}(j).\n",
    "$$\n",
    "$$\n",
    "\\gamma_t(k)=P(Z_t=k\\mid X_{1:T})\n",
    "=\n",
    "\\frac{\\alpha_t(k)\\beta_t(k)}{\\sum_{\\ell=0}^{K-1}\\alpha_t(\\ell)\\beta_t(\\ell)}.\n",
    "$$\n",
    "$$\n",
    "\\xi_t(i,j)=P(Z_t=i,Z_{t+1}=j\\mid X_{1:T})\n",
    "=\n",
    "\\frac{\\alpha_t(i)A_{ij}b_j(X_{t+1})\\beta_{t+1}(j)}\n",
    "{\\sum_{p=0}^{K-1}\\sum_{q=0}^{K-1}\\alpha_t(p)A_{pq}b_q(X_{t+1})\\beta_{t+1}(q)}.\n",
    "$$\n",
    "\n",
    "**M-step (update rules)**\n",
    "$$\n",
    "\\pi_k^{new}=\\gamma_1(k),\n",
    "\\qquad\n",
    "A_{ij}^{new}=\\frac{\\sum_{t=1}^{T-1}\\xi_t(i,j)}{\\sum_{t=1}^{T-1}\\gamma_t(i)}.\n",
    "$$\n",
    "$$\n",
    "\\mu_k^{new}=\\frac{\\sum_{t=1}^{T}\\gamma_t(k)X_t}{\\sum_{t=1}^{T}\\gamma_t(k)}.\n",
    "$$\n",
    "$$\n",
    "\\Sigma_k^{new}\n",
    "=\n",
    "\\frac{\\sum_{t=1}^{T}\\gamma_t(k)(X_t-\\mu_k^{new})(X_t-\\mu_k^{new})^\\top}\n",
    "{\\sum_{t=1}^{T}\\gamma_t(k)}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Goal 2: Posterior state probabilities (smoothing)\n",
    "\n",
    "For each time $\\tau$:\n",
    "$$\n",
    "\\gamma_\\tau(k)=P(Z_\\tau=k\\mid X_{1:T},\\hat\\theta)\n",
    "=\n",
    "\\frac{\\alpha_\\tau(k)\\beta_\\tau(k)}{\\sum_{j=0}^{K-1}\\alpha_\\tau(j)\\beta_\\tau(j)}.\n",
    "$$\n",
    "\n",
    "**One-step-ahead state probability (used in code)**\n",
    "$$\n",
    "P(Z_{T+1}=\\cdot\\mid X_{1:T},\\hat\\theta)=\\gamma_T^\\top A.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Goal 3: Next-step mean/std and downside risk (matches your code)\n",
    "\n",
    "We fit the HMM on standardized data $X'$:\n",
    "$$\n",
    "X'=\\frac{X-m}{s}\n",
    "\\quad\\Longleftrightarrow\\quad\n",
    "X=m+sX',\n",
    "\\qquad\n",
    "m=\\texttt{scaler.mean\\_},\\; s=\\texttt{scaler.scale\\_}.\n",
    "$$\n",
    "\n",
    "If state $k$ has (in standardized space)\n",
    "$$\n",
    "X'\\mid (Z=k)\\sim \\mathcal N(\\mu_k',(\\sigma_k')^2),\n",
    "$$\n",
    "then in original units:\n",
    "$$\n",
    "\\mu_k=m+s\\mu_k',\n",
    "\\qquad\n",
    "\\sigma_k=s\\sigma_k',\n",
    "\\qquad\n",
    "\\sigma_k'=\\sqrt{(\\sigma_k')^2}.\n",
    "$$\n",
    "\n",
    "**Downside second moment for a Gaussian (threshold $0$)**  \n",
    "Let $X\\sim\\mathcal N(\\mu,\\sigma^2)$ and define\n",
    "$$\n",
    "z=\\frac{0-\\mu}{\\sigma}=-\\frac{\\mu}{\\sigma}.\n",
    "$$\n",
    "Then\n",
    "$$\n",
    "\\mathbb E\\!\\left[X^2\\mathbf 1_{\\{X<0\\}}\\right]\n",
    "=\n",
    "(\\mu^2+\\sigma^2)\\Phi(z)-\\mu\\sigma\\,\\phi(z),\n",
    "$$\n",
    "where $\\Phi$ is the standard normal CDF and $\\phi$ is the PDF.\n",
    "\n",
    "For each state $k$, define\n",
    "$$\n",
    "d_k=(\\mu_k^2+\\sigma_k^2)\\Phi\\!\\Big(-\\frac{\\mu_k}{\\sigma_k}\\Big)\n",
    "-\\mu_k\\sigma_k\\,\\phi\\!\\Big(-\\frac{\\mu_k}{\\sigma_k}\\Big).\n",
    "$$\n",
    "\n",
    "**Next-state probabilities**  \n",
    "If $\\mathbf p_t$ is the current state probability row vector, then\n",
    "$$\n",
    "\\mathbf p_{t+1}=\\mathbf p_t A.\n",
    "$$\n",
    "(In code this is `next_states_prob`.)\n",
    "\n",
    "**Expected mean (next step)**\n",
    "$$\n",
    "\\mathbb E[X_{t+1}\\mid X_{1:t}]\n",
    "=\n",
    "\\sum_{k=0}^{K-1} p_{t+1}(k)\\mu_k.\n",
    "$$\n",
    "\n",
    "**Expected variance and std (next step)**  \n",
    "First compute the mixture second moment:\n",
    "$$\n",
    "\\mathbb E[X_{t+1}^2\\mid X_{1:t}]\n",
    "=\n",
    "\\sum_{k=0}^{K-1} p_{t+1}(k)\\big(\\sigma_k^2+\\mu_k^2\\big).\n",
    "$$\n",
    "Then\n",
    "$$\n",
    "\\mathrm{Var}(X_{t+1}\\mid X_{1:t})\n",
    "=\n",
    "\\mathbb E[X_{t+1}^2\\mid X_{1:t}]\n",
    "-\n",
    "\\Big(\\mathbb E[X_{t+1}\\mid X_{1:t}]\\Big)^2,\n",
    "$$\n",
    "$$\n",
    "\\mathrm{Std}(X_{t+1}\\mid X_{1:t})\n",
    "=\n",
    "\\sqrt{\\max(\\mathrm{Var}(\\cdot),\\varepsilon)}.\n",
    "$$\n",
    "\n",
    "**Expected downside deviation (next step, target $0$)**  \n",
    "Mix the downside second moments:\n",
    "$$\n",
    "\\mathbb E[X_{t+1}^2\\mathbf 1_{\\{X_{t+1}<0\\}}\\mid X_{1:t}]\n",
    "=\n",
    "\\sum_{k=0}^{K-1} p_{t+1}(k)d_k.\n",
    "$$\n",
    "Define downside std:\n",
    "$$\n",
    "\\mathrm{DownStd}(X_{t+1}\\mid X_{1:t})\n",
    "=\n",
    "\\sqrt{\\max\\!\\Big(\\sum_{k=0}^{K-1} p_{t+1}(k)d_k,\\varepsilon\\Big)}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250855a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from hmmlearn.hmm import GaussianHMM, GMMHMM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import norm\n",
    "import yfinance as yf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def data_preparation(tickers, period=\"30y\", window_size=5, ma_size=20, interval=\"1d\"):\n",
    "    assets = {}\n",
    "    assets_oo = {}\n",
    "    for ticker in tickers:\n",
    "        assets[ticker]    = yf.download(ticker, period=period, interval=interval, auto_adjust=True, progress=False)[\"Close\"]\n",
    "        assets_oo[ticker] = yf.download(ticker, period=period, interval=interval, auto_adjust=True, progress=False)[\"Close\"].pct_change().shift(-1)  # For calculating entry position at t\n",
    "        assets[ticker].columns    = [f\"{ticker}_Close\"]\n",
    "        assets_oo[ticker].columns = [f\"{ticker}_oo\"]\n",
    "        assets[ticker][f\"{ticker}_ret\"]           = assets[ticker][f\"{ticker}_Close\"].pct_change()\n",
    "        assets[ticker][f\"{ticker}_std\"]           = assets[ticker][f\"{ticker}_ret\"].rolling(window=window_size).std()\n",
    "        assets[ticker][f\"{ticker}_ewma_ret\"]      = assets[ticker][f\"{ticker}_Close\"].ewm(span=window_size, adjust=False).mean().pct_change()\n",
    "        assets[ticker][f\"{ticker}_ewma_down_std\"] = assets[ticker][f\"{ticker}_ewma_ret\"].where(assets[ticker][f\"{ticker}_ewma_ret\"] < 0, 0).rolling(window=ma_size).std()\n",
    "    rets_oo = pd.concat([assets_oo[ticker] for ticker in tickers], axis=1)\n",
    "    df = pd.concat([assets[ticker] for ticker in tickers] + [rets_oo], axis=1, join=\"inner\").dropna()\n",
    "    return df\n",
    "\n",
    "\n",
    "def num_states_selection(tickers, df, n_states, past_data_size=int(252*3)):\n",
    "    print(f\"Number of states: {n_states}, Number of years data: {int(past_data_size/252)}\")\n",
    "    for ticker in tickers:\n",
    "        X_raw = df[[f\"{ticker}_ewma_ret\"]].values[:past_data_size+1]\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_raw)\n",
    "        model = GaussianHMM(n_components=n_states, covariance_type=\"diag\", n_iter=500, tol=1e-3, min_covar=1e-3).fit(X_train)\n",
    "        #model = GMMHMM(n_components=n_states, n_mix=2, covariance_type=\"diag\", n_iter=500, tol=1e-3, min_covar=1e-3).fit(X_train)\n",
    "        aic_score = round(model.aic(X_train), 4)\n",
    "        bic_score = round(model.bic(X_train), 4)\n",
    "        print(f\"{ticker}: AIC: {aic_score}, BIC:{bic_score}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "# 1. Try n_states=3/4\n",
    "def hmm_weight(tickers, df, n_states=4, past_data_size=int(252*3), fit_dist_size=int(252/3), accumulation_size=40, gap_prob=0.5, ret_thres=-0.005, capped_score=1, seed=42, n_iters=500, n_restarts=40):\n",
    "    X_raws, X_raw_ret, X_raw_std, scalers, models, scores, weight = {}, {}, {}, {}, {}, {}, {}\n",
    "    accumulation_number = 0\n",
    "    weight_list = np.zeros(shape=(len(df), len(tickers)))\n",
    "    for ticker in tickers:\n",
    "        X_raws[ticker] = df[[f\"{ticker}_ewma_ret\"]].values\n",
    "        X_raw_ret[ticker] = df[[f\"{ticker}_ret\"]].values\n",
    "        X_raw_std[ticker] = df[[f\"{ticker}_ewma_down_std\"]].values\n",
    "\n",
    "    for t in range(past_data_size, len(df)):\n",
    "        sum_scores = 0\n",
    "        for ticker in tickers:\n",
    "            X_raw_trains = X_raws[ticker][t-past_data_size+1:t+1]\n",
    "\n",
    "            # Training Day \n",
    "            if accumulation_number == 0: \n",
    "                scalers[ticker] = StandardScaler()\n",
    "                X_trains = scalers[ticker].fit_transform(X_raw_trains)\n",
    "                hmm_models = [GaussianHMM(n_components=n_states, covariance_type=\"diag\", n_iter=n_iters, tol=1e-3, min_covar=1e-3, random_state=seed+i).fit(X_trains) for i in range(n_restarts)]\n",
    "                #hmm_models = [GMMHMM(n_components=n_states, n_mix=2, covariance_type=\"diag\", n_iter=100, tol=1e-3, min_covar=1e-3, random_state=seed+i).fit(X_trains) for i in range(n_restarts)]\n",
    "                models[ticker] = max(hmm_models, key=lambda m: m.score(X_trains))\n",
    "\n",
    "            # Non-Training Day\n",
    "            else:\n",
    "                X_trains = scalers[ticker].transform(X_raw_trains)\n",
    "\n",
    "            state_posterior_prob = models[ticker].predict_proba(X_trains)\n",
    "            next_states_prob = state_posterior_prob[-1] @ models[ticker].transmat_\n",
    "\n",
    "            \"\"\"            \n",
    "            states = models[ticker].predict(X_trains)\n",
    "            mean               = [X_raw_trains[-fit_dist_size: ][states[-fit_dist_size: ] == s, 0].mean()                     for s in range(n_states)] \n",
    "            var                = [X_raw_trains[-fit_dist_size: ][states[-fit_dist_size: ] == s, 0].var()                      for s in range(n_states)]\n",
    "            down_second_moment = [np.mean(np.minimum(0.0, X_raw_trains[-fit_dist_size:][states[-fit_dist_size:] == s, 0])**2) for s in range(n_states)]\n",
    "            \n",
    "            gamma_fit = state_posterior_prob[-fit_dist_size:]\n",
    "            #X_raw_fit = X_raw_trains[-fit_dist_size:, 0]\n",
    "            X_raw_fit = X_raw_ret[ticker][t-fit_dist_size+1:t+1, 0]\n",
    "            mean               = (gamma_fit.T @ X_raw_fit)                          / (gamma_fit.sum(axis=0) + 1e-12)\n",
    "            var                = (gamma_fit.T @ ((X_raw_fit[:, None] - mean) ** 2)) / (gamma_fit.sum(axis=0) + 1e-12)\n",
    "            down_second_moment = (gamma_fit.T @ (np.minimum(0.0, X_raw_fit) ** 2))  / (gamma_fit.sum(axis=0) + 1e-12)\n",
    "\n",
    "            expected_mean_next_state     = np.array(mean) @ next_states_prob\n",
    "            expected_std_next_state      = np.sqrt((var + (mean - expected_mean_next_state) ** 2) @ next_states_prob + 1e-12)\n",
    "            expected_down_std_next_state = np.sqrt(np.array(down_second_moment) @ next_states_prob + 1e-12)\n",
    "            \"\"\"\n",
    "            \n",
    "            #mean               = scalers[ticker].mean_ + scalers[ticker].scale_ * models[ticker].means_\n",
    "            #std                = scalers[ticker].scale_ * np.sqrt(models[ticker].covars_)\n",
    "            mean               = scalers[ticker].mean_[0] + scalers[ticker].scale_[0] * models[ticker].means_.ravel()\n",
    "            std                = scalers[ticker].scale_[0] * np.sqrt(models[ticker].covars_.ravel())\n",
    "            z                  = -mean / np.maximum(std, 1e-12)\n",
    "            down_second_moment = (mean**2 + std**2) * norm.cdf(z) - (mean * std) * norm.pdf(z)\n",
    "\n",
    "            expected_mean_next_state     = float(next_states_prob @ mean)\n",
    "            expected_var_next_state      = float(next_states_prob @ (std**2 + mean**2) - expected_mean_next_state**2)\n",
    "            expected_std_next_state      = float(np.sqrt(max(expected_var_next_state, 1e-12)))\n",
    "            expected_down_std_next_state = float(np.sqrt(max(next_states_prob @ down_second_moment, 1e-12)))\n",
    "\n",
    "            expected_sharpe_next_state   = expected_mean_next_state / expected_std_next_state\n",
    "            expected_sortino_next_state  = expected_mean_next_state / expected_down_std_next_state\n",
    "\n",
    "            crash_state_idx = np.argmin(mean)\n",
    "            crash_state_mean = mean[crash_state_idx]\n",
    "            highest_prob_next_state_idx = np.argmax(next_states_prob)\n",
    "            scores[ticker] = expected_sortino_next_state if (expected_sortino_next_state > 0 and next_states_prob[highest_prob_next_state_idx] > next_states_prob[crash_state_idx] + gap_prob) else -np.inf\n",
    "\n",
    "            \"\"\"\n",
    "            if crash_state_mean > 0:\n",
    "                scores[ticker] = expected_sortino_next_state\n",
    "            else:\n",
    "                if next_states_prob[highest_prob_next_state_idx] > next_states_prob[crash_state_idx] + gap_prob:\n",
    "                    if expected_mean_next_state > 0:\n",
    "                        scores[ticker] = expected_sortino_next_state\n",
    "                    elif (expected_mean_next_state > ret_thres and expected_down_std_next_state < float(X_raw_std[ticker][t].item())):\n",
    "                        scores[ticker] = min((expected_mean_next_state - ret_thres) / expected_down_std_next_state, capped_score)\n",
    "                    else:\n",
    "                        scores[ticker] = -np.inf\n",
    "                else:\n",
    "                    scores[ticker] = -np.inf         \n",
    "            print(\n",
    "                ticker,\n",
    "                \"mean: \", round(expected_mean_next_state, 4),\n",
    "                \"down_std: \", round(expected_down_std_next_state, 4),\n",
    "                \"ma_std: \", round(float(X_raw_std[ticker][t].item()), 4),\n",
    "                \"score: \", scores[ticker]\n",
    "            )\"\"\"\n",
    "            if np.isfinite(scores[ticker]): sum_scores += scores[ticker]\n",
    "\n",
    "        for ticker_col, ticker in enumerate(tickers):\n",
    "            if np.isfinite(scores[ticker]): weight_list[t][ticker_col] = scores[ticker] / sum_scores\n",
    "        \n",
    "        print(\"weight at \", t, \": \", weight_list[t])\n",
    "        accumulation_number += 1\n",
    "        if accumulation_number == accumulation_size: \n",
    "            accumulation_number = 0;\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        weight[ticker] = pd.Series(weight_list[:, tickers.index(ticker)], index=df.index)\n",
    "    df[\"port_oo\"] = sum([weight[ticker] * df[f\"{ticker}_oo\"] for ticker in tickers])\n",
    "    ret_df = df[[f\"{ticker}_oo\" for ticker in tickers] + [\"port_oo\"]].iloc[past_data_size:]\n",
    "    cash_proportion = (weight_list[past_data_size:].sum(axis=1) == 0).mean()\n",
    "    print(f\"Cash Proportion: {cash_proportion:.2%}\\n\")\n",
    "    return ret_df\n",
    "\n",
    "\n",
    "def overall_return_matrics(returns, window=252):\n",
    "    annual_mean = returns.mean() * window\n",
    "    annual_std = returns.std() * np.sqrt(window)\n",
    "    annual_down_std = np.sqrt(np.mean(np.minimum(0.0, returns)**2)) * np.sqrt(window)\n",
    "    annual_sharpe = annual_mean / annual_std\n",
    "    annual_sortino = annual_mean / annual_down_std\n",
    "\n",
    "    rolling_mean = returns.rolling(window).mean()\n",
    "    rolling_std = returns.rolling(window).std()\n",
    "    rolling_sharpe = np.sqrt(window) * rolling_mean / rolling_std\n",
    "\n",
    "    cumprod = (1 + returns).cumprod()\n",
    "    cumprod_max = cumprod.cummax()\n",
    "    dd = (cumprod - cumprod_max) / cumprod_max\n",
    "    max_dd = dd.min()\n",
    "\n",
    "    return cumprod, rolling_mean, rolling_std, rolling_sharpe, annual_mean, annual_std, annual_sharpe, annual_sortino, max_dd\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f54e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\"QQQ\", \"GLD\", \"CHFJPY=X\"]\n",
    "df = data_preparation(tickers)\n",
    "for yr in range(2,6):\n",
    "    for n in range(2,6):\n",
    "        num_states_selection(tickers, df, n, past_data_size=int(252*yr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dff6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_df = hmm_weight(tickers, df)\n",
    "cumprods, rolling_means, rolling_stds, rolling_sharpes, tot_means, tot_stds, tot_sharpes, tot_sortinos, max_dds = {}, {}, {}, {}, {}, {}, {}, {}, {}\n",
    "port_cumprod, port_rolling_mean, port_rolling_std, port_rolling_sharpe, port_tot_mean, port_tot_std, port_tot_sharpe, port_tot_sortino, port_max_dd = overall_return_matrics(ret_df[\"port_oo\"])\n",
    "for ticker in tickers:\n",
    "    cumprods[ticker], rolling_means[ticker], rolling_stds[ticker], rolling_sharpes[ticker], tot_means[ticker], tot_stds[ticker], tot_sharpes[ticker], tot_sortinos[ticker], max_dds[ticker] = overall_return_matrics(ret_df[f\"{ticker}_oo\"])\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Equity curve (cumprod)\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(port_cumprod.index, port_cumprod.values, label=\"Portfolio\")\n",
    "for ticker in tickers:\n",
    "    plt.plot(cumprods[ticker].index, cumprods[ticker].values, label=ticker)\n",
    "plt.title(\"Equity Curve (Cumprod)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Equity (Start = 1.0)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Portfolio rolling sharpe\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(port_rolling_sharpe.index, port_rolling_sharpe.values, label=\"port_rolling_sharpe\")\n",
    "plt.title(\"Portfolio Rolling Sharpe\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Summary table: mean / std / sharpe / max_dd\n",
    "# -----------------------------\n",
    "summary_df = pd.DataFrame({\n",
    "        \"mean\":   [port_tot_mean]   + [tot_means[ticker]   for ticker in tickers],\n",
    "        \"std\":    [port_tot_std]    + [tot_stds[ticker]    for ticker in tickers],\n",
    "        \"sharpe\": [port_tot_sharpe] + [tot_sharpes[ticker] for ticker in tickers],\n",
    "        \"sortino\":[port_tot_sortino]+ [tot_sortinos[ticker]for ticker in tickers],\n",
    "        \"max_dd\": [port_max_dd]     + [max_dds[ticker]     for ticker in tickers],\n",
    "    }, index=[\"Portfolio\"] + list(tickers),\n",
    ")\n",
    "\n",
    "display(summary_df)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
